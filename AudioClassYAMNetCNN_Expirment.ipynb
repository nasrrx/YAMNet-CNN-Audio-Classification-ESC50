{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nasrr\\Desktop\\myenv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d5f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            filename  fold  target        category  esc10  src_file take\n",
      "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
      "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
      "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
      "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
      "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A\n"
     ]
    }
   ],
   "source": [
    "# üìÅ Step 3: Load ESC-50 CSV\n",
    "# ‚úÖ Update these paths with your actual file structure\n",
    "CSV_PATH = r'C:\\Users\\nasrr\\Desktop\\CNN_Projects\\AudioClassifier\\ESC-50-master\\ESC-50-master\\meta\\esc50.csv'\n",
    "AUDIO_PATH = r'C:\\Users\\nasrr\\Desktop\\CNN_Projects\\AudioClassifier\\ESC-50-master\\ESC-50-master\\audio'\n",
    "\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c6eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nasrr\\Desktop\\myenv\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nasrr\\Desktop\\myenv\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nasrr\\Desktop\\myenv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nasrr\\Desktop\\myenv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üîâ Step 4: Load YAMNet model\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424311db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:41<00:00, 48.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done:  (2000, 1024) (2000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# üéß Step 5: Convert audio to embeddings (X) and labels (y)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    file_path = os.path.join(AUDIO_PATH, row['filename'])\n",
    "    label = row['target']\n",
    "\n",
    "    try:\n",
    "        waveform, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "        waveform = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
    "\n",
    "        _, embeddings, _ = yamnet_model(waveform)\n",
    "        mean_embedding = tf.reduce_mean(embeddings, axis=0).numpy()\n",
    "\n",
    "        X.append(mean_embedding)\n",
    "        y.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {file_path} ‚Üí {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"‚úÖ Done: \", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a9482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1600, 1024) Test: (400, 1024)\n"
     ]
    }
   ],
   "source": [
    "# üß† Step 6: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697afccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=2000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üß™ Step 7: Train Classifier\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37464bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation Accuracy: 87.50%\n",
      "\n",
      "Detailed Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       0.89      1.00      0.94         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       0.88      0.88      0.88         8\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       1.00      0.88      0.93         8\n",
      "           7       0.80      1.00      0.89         8\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00         8\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         8\n",
      "          12       0.89      1.00      0.94         8\n",
      "          13       0.67      0.50      0.57         8\n",
      "          14       0.88      0.88      0.88         8\n",
      "          15       0.73      1.00      0.84         8\n",
      "          16       0.80      0.50      0.62         8\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      0.88      0.93         8\n",
      "          19       0.70      0.88      0.78         8\n",
      "          20       1.00      1.00      1.00         8\n",
      "          21       0.64      0.88      0.74         8\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       1.00      0.62      0.77         8\n",
      "          24       0.89      1.00      0.94         8\n",
      "          25       0.89      1.00      0.94         8\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       0.89      1.00      0.94         8\n",
      "          28       0.89      1.00      0.94         8\n",
      "          29       1.00      0.88      0.93         8\n",
      "          30       1.00      0.75      0.86         8\n",
      "          31       0.67      0.75      0.71         8\n",
      "          32       1.00      0.75      0.86         8\n",
      "          33       0.86      0.75      0.80         8\n",
      "          34       0.78      0.88      0.82         8\n",
      "          35       0.50      0.50      0.50         8\n",
      "          36       1.00      1.00      1.00         8\n",
      "          37       1.00      0.88      0.93         8\n",
      "          38       1.00      0.88      0.93         8\n",
      "          39       1.00      1.00      1.00         8\n",
      "          40       0.50      0.25      0.33         8\n",
      "          41       1.00      1.00      1.00         8\n",
      "          42       0.83      0.62      0.71         8\n",
      "          43       0.62      1.00      0.76         8\n",
      "          44       0.75      0.75      0.75         8\n",
      "          45       1.00      1.00      1.00         8\n",
      "          46       1.00      1.00      1.00         8\n",
      "          47       0.60      0.75      0.67         8\n",
      "          48       0.75      0.75      0.75         8\n",
      "          49       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.87       400\n",
      "weighted avg       0.88      0.88      0.87       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üìä Step 8: Evaluate Model\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"‚úÖ Validation Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nDetailed Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "\n",
    "augment = torch.nn.Sequential(\n",
    "    T.FrequencyMasking(freq_mask_param=10),\n",
    "    T.TimeMasking(time_mask_param=20)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [01:01<00:00, 32.68it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_FRAMES = 100  # We'll fix all embeddings to this length\n",
    "\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    file_path = os.path.join(AUDIO_PATH, row['filename'])\n",
    "    label = row['target']\n",
    "\n",
    "    try:\n",
    "        waveform, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "        waveform = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
    "\n",
    "        _, embeddings, _ = yamnet_model(waveform)\n",
    "        emb_np = embeddings.numpy()  # shape: (frames, 1024)\n",
    "\n",
    "        # Pad/truncate to MAX_FRAMES\n",
    "        if emb_np.shape[0] < MAX_FRAMES:\n",
    "            pad_width = MAX_FRAMES - emb_np.shape[0]\n",
    "            emb_np = np.pad(emb_np, ((0, pad_width), (0, 0)), mode='constant')\n",
    "        else:\n",
    "            emb_np = emb_np[:MAX_FRAMES, :]\n",
    "\n",
    "        X_seq.append(emb_np)\n",
    "        y_seq.append(label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {file_path} ‚Üí {e}\")\n",
    "\n",
    "X_seq = np.array(X_seq)  # shape: (N, 100, 1024)\n",
    "y_seq = np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4aae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, stratify=y_seq, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# DataLoaders\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "val_pct = 0.1\n",
    "val_size = int(val_pct * len(train_ds))\n",
    "train_size = len(train_ds) - val_size\n",
    "\n",
    "train_set, val_set = random_split(train_ds, [train_size, val_size])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YAMNet1DCNN(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1024, 512, kernel_size=5, padding=2) # 1024 Features \n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(512, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(256, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, 100, 1024) ‚Üí (B, 1024, 100)\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x)  # üîπ ADD THIS\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.squeeze(-1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9733b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class YAMNet1DCNN_Improved(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1024, 512, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(512, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(256, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.85)  # Slightly higher for better regularization\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, 100, 1024) ‚Üí (B, 1024, 100)\n",
    "        x = self.pool1(F.gelu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.gelu(self.bn2(self.conv2(x))))\n",
    "        x = F.gelu(self.bn3(self.conv3(x)))\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84025f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=175.96, Train Acc=4.72%, Val Acc=22.50%\n",
      "Epoch 2: Loss=156.49, Train Acc=14.72%, Val Acc=38.12%\n",
      "Epoch 3: Loss=137.34, Train Acc=29.93%, Val Acc=51.88%\n",
      "Epoch 4: Loss=117.24, Train Acc=42.71%, Val Acc=52.50%\n",
      "Epoch 5: Loss=105.16, Train Acc=49.51%, Val Acc=62.50%\n",
      "Epoch 6: Loss=95.39, Train Acc=54.03%, Val Acc=65.62%\n",
      "Epoch 7: Loss=85.45, Train Acc=59.17%, Val Acc=66.88%\n",
      "Epoch 8: Loss=78.09, Train Acc=63.40%, Val Acc=71.25%\n",
      "Epoch 9: Loss=72.35, Train Acc=67.92%, Val Acc=71.88%\n",
      "Epoch 10: Loss=68.59, Train Acc=67.99%, Val Acc=72.50%\n",
      "Epoch 11: Loss=63.12, Train Acc=70.00%, Val Acc=71.88%\n",
      "Epoch 12: Loss=60.53, Train Acc=70.00%, Val Acc=78.12%\n",
      "Epoch 13: Loss=56.07, Train Acc=73.82%, Val Acc=77.50%\n",
      "Epoch 14: Loss=50.26, Train Acc=75.35%, Val Acc=77.50%\n",
      "Epoch 15: Loss=49.39, Train Acc=75.49%, Val Acc=79.38%\n",
      "Epoch 16: Loss=46.57, Train Acc=77.01%, Val Acc=80.00%\n",
      "Epoch 17: Loss=45.33, Train Acc=77.36%, Val Acc=81.25%\n",
      "Epoch 18: Loss=41.15, Train Acc=81.67%, Val Acc=80.00%\n",
      "Epoch 19: Loss=38.99, Train Acc=81.25%, Val Acc=79.38%\n",
      "Epoch 20: Loss=38.28, Train Acc=81.60%, Val Acc=81.25%\n",
      "Epoch 21: Loss=36.21, Train Acc=83.06%, Val Acc=82.50%\n",
      "Epoch 22: Loss=33.60, Train Acc=84.10%, Val Acc=85.00%\n",
      "‚úÖ Saved model: Model_85_00_Epoch22.pt (Val Acc: 85.00%)\n",
      "Epoch 23: Loss=33.13, Train Acc=83.47%, Val Acc=84.38%\n",
      "Epoch 24: Loss=30.25, Train Acc=86.88%, Val Acc=82.50%\n",
      "Epoch 25: Loss=29.85, Train Acc=86.18%, Val Acc=85.62%\n",
      "‚úÖ Saved model: Model_85_62_Epoch25.pt (Val Acc: 85.62%)\n",
      "Epoch 26: Loss=29.56, Train Acc=85.14%, Val Acc=86.25%\n",
      "‚úÖ Saved model: Model_86_25_Epoch26.pt (Val Acc: 86.25%)\n",
      "Epoch 27: Loss=29.51, Train Acc=85.42%, Val Acc=85.62%\n",
      "‚úÖ Saved model: Model_85_62_Epoch27.pt (Val Acc: 85.62%)\n",
      "Epoch 28: Loss=29.08, Train Acc=85.76%, Val Acc=83.12%\n",
      "Epoch 29: Loss=26.31, Train Acc=86.88%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch29.pt (Val Acc: 88.12%)\n",
      "Epoch 30: Loss=25.49, Train Acc=87.29%, Val Acc=86.25%\n",
      "‚úÖ Saved model: Model_86_25_Epoch30.pt (Val Acc: 86.25%)\n",
      "Epoch 31: Loss=23.58, Train Acc=88.82%, Val Acc=81.25%\n",
      "Epoch 32: Loss=22.53, Train Acc=89.51%, Val Acc=85.00%\n",
      "‚úÖ Saved model: Model_85_00_Epoch32.pt (Val Acc: 85.00%)\n",
      "Epoch 33: Loss=22.36, Train Acc=89.38%, Val Acc=83.75%\n",
      "Epoch 34: Loss=21.26, Train Acc=89.10%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch34.pt (Val Acc: 88.12%)\n",
      "Epoch 35: Loss=20.71, Train Acc=89.51%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch35.pt (Val Acc: 87.50%)\n",
      "Epoch 36: Loss=18.93, Train Acc=91.74%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch36.pt (Val Acc: 87.50%)\n",
      "Epoch 37: Loss=18.05, Train Acc=91.32%, Val Acc=86.88%\n",
      "‚úÖ Saved model: Model_86_88_Epoch37.pt (Val Acc: 86.88%)\n",
      "Epoch 38: Loss=20.06, Train Acc=90.83%, Val Acc=84.38%\n",
      "Epoch 39: Loss=18.45, Train Acc=90.83%, Val Acc=86.25%\n",
      "‚úÖ Saved model: Model_86_25_Epoch39.pt (Val Acc: 86.25%)\n",
      "Epoch 40: Loss=19.30, Train Acc=90.90%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch40.pt (Val Acc: 88.75%)\n",
      "Epoch 41: Loss=17.65, Train Acc=91.67%, Val Acc=86.25%\n",
      "‚úÖ Saved model: Model_86_25_Epoch41.pt (Val Acc: 86.25%)\n",
      "Epoch 42: Loss=17.55, Train Acc=91.81%, Val Acc=83.75%\n",
      "Epoch 43: Loss=15.52, Train Acc=92.99%, Val Acc=86.88%\n",
      "‚úÖ Saved model: Model_86_88_Epoch43.pt (Val Acc: 86.88%)\n",
      "Epoch 44: Loss=16.19, Train Acc=92.29%, Val Acc=86.25%\n",
      "‚úÖ Saved model: Model_86_25_Epoch44.pt (Val Acc: 86.25%)\n",
      "Epoch 45: Loss=16.78, Train Acc=91.11%, Val Acc=86.25%\n",
      "‚úÖ Saved model: Model_86_25_Epoch45.pt (Val Acc: 86.25%)\n",
      "Epoch 46: Loss=14.37, Train Acc=92.85%, Val Acc=86.88%\n",
      "‚úÖ Saved model: Model_86_88_Epoch46.pt (Val Acc: 86.88%)\n",
      "Epoch 47: Loss=14.53, Train Acc=92.57%, Val Acc=86.25%\n",
      "‚úÖ Saved model: Model_86_25_Epoch47.pt (Val Acc: 86.25%)\n",
      "Epoch 48: Loss=12.84, Train Acc=93.96%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch48.pt (Val Acc: 87.50%)\n",
      "Epoch 49: Loss=13.08, Train Acc=93.47%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch49.pt (Val Acc: 87.50%)\n",
      "Epoch 50: Loss=13.60, Train Acc=94.31%, Val Acc=86.88%\n",
      "‚úÖ Saved model: Model_86_88_Epoch50.pt (Val Acc: 86.88%)\n",
      "Epoch 51: Loss=11.80, Train Acc=94.38%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch51.pt (Val Acc: 88.12%)\n",
      "Epoch 52: Loss=12.03, Train Acc=94.58%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch52.pt (Val Acc: 87.50%)\n",
      "Epoch 53: Loss=13.07, Train Acc=93.75%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch53.pt (Val Acc: 88.12%)\n",
      "Epoch 54: Loss=11.42, Train Acc=94.93%, Val Acc=85.62%\n",
      "‚úÖ Saved model: Model_85_62_Epoch54.pt (Val Acc: 85.62%)\n",
      "Epoch 55: Loss=10.76, Train Acc=94.86%, Val Acc=86.88%\n",
      "‚úÖ Saved model: Model_86_88_Epoch55.pt (Val Acc: 86.88%)\n",
      "Epoch 56: Loss=11.46, Train Acc=94.72%, Val Acc=86.25%\n",
      "‚úÖ Saved model: Model_86_25_Epoch56.pt (Val Acc: 86.25%)\n",
      "Epoch 57: Loss=9.08, Train Acc=96.11%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch57.pt (Val Acc: 87.50%)\n",
      "Epoch 58: Loss=7.47, Train Acc=96.94%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch58.pt (Val Acc: 88.12%)\n",
      "Epoch 59: Loss=7.10, Train Acc=97.15%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch59.pt (Val Acc: 88.12%)\n",
      "Epoch 60: Loss=7.82, Train Acc=96.46%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch60.pt (Val Acc: 88.12%)\n",
      "Epoch 61: Loss=6.85, Train Acc=96.74%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch61.pt (Val Acc: 88.12%)\n",
      "Epoch 62: Loss=7.03, Train Acc=97.43%, Val Acc=86.88%\n",
      "‚úÖ Saved model: Model_86_88_Epoch62.pt (Val Acc: 86.88%)\n",
      "Epoch 63: Loss=6.83, Train Acc=97.57%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch63.pt (Val Acc: 87.50%)\n",
      "Epoch 64: Loss=6.71, Train Acc=97.50%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch64.pt (Val Acc: 88.75%)\n",
      "Epoch 65: Loss=5.70, Train Acc=97.85%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch65.pt (Val Acc: 88.12%)\n",
      "Epoch 66: Loss=6.20, Train Acc=97.64%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch66.pt (Val Acc: 88.12%)\n",
      "Epoch 67: Loss=5.13, Train Acc=98.40%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch67.pt (Val Acc: 88.75%)\n",
      "Epoch 68: Loss=5.70, Train Acc=98.06%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch68.pt (Val Acc: 88.12%)\n",
      "Epoch 69: Loss=5.22, Train Acc=98.61%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch69.pt (Val Acc: 88.75%)\n",
      "Epoch 70: Loss=5.10, Train Acc=98.26%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch70.pt (Val Acc: 88.75%)\n",
      "Epoch 71: Loss=5.32, Train Acc=98.47%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch71.pt (Val Acc: 88.75%)\n",
      "Epoch 72: Loss=5.48, Train Acc=98.12%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch72.pt (Val Acc: 88.12%)\n",
      "Epoch 73: Loss=4.89, Train Acc=98.75%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch73.pt (Val Acc: 88.12%)\n",
      "Epoch 74: Loss=4.15, Train Acc=98.75%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch74.pt (Val Acc: 88.75%)\n",
      "Epoch 75: Loss=4.36, Train Acc=98.82%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch75.pt (Val Acc: 88.12%)\n",
      "Epoch 76: Loss=4.17, Train Acc=98.54%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch76.pt (Val Acc: 88.12%)\n",
      "Epoch 77: Loss=4.27, Train Acc=98.96%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch77.pt (Val Acc: 88.12%)\n",
      "Epoch 78: Loss=3.99, Train Acc=98.96%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch78.pt (Val Acc: 88.75%)\n",
      "Epoch 79: Loss=3.42, Train Acc=99.31%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch79.pt (Val Acc: 88.75%)\n",
      "Epoch 80: Loss=3.62, Train Acc=98.82%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch80.pt (Val Acc: 88.75%)\n",
      "Epoch 81: Loss=3.93, Train Acc=99.24%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch81.pt (Val Acc: 88.75%)\n",
      "Epoch 82: Loss=3.13, Train Acc=99.51%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch82.pt (Val Acc: 88.75%)\n",
      "Epoch 83: Loss=3.54, Train Acc=99.03%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch83.pt (Val Acc: 88.75%)\n",
      "Epoch 84: Loss=3.69, Train Acc=99.10%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch84.pt (Val Acc: 88.75%)\n",
      "Epoch 85: Loss=3.28, Train Acc=99.03%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch85.pt (Val Acc: 88.12%)\n",
      "Epoch 86: Loss=3.19, Train Acc=99.17%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch86.pt (Val Acc: 88.12%)\n",
      "Epoch 87: Loss=3.24, Train Acc=99.31%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch87.pt (Val Acc: 88.12%)\n",
      "Epoch 88: Loss=3.02, Train Acc=99.58%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch88.pt (Val Acc: 88.12%)\n",
      "Epoch 89: Loss=2.99, Train Acc=98.96%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch89.pt (Val Acc: 88.75%)\n",
      "Epoch 90: Loss=2.78, Train Acc=99.38%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch90.pt (Val Acc: 88.75%)\n",
      "Epoch 91: Loss=2.93, Train Acc=99.51%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch91.pt (Val Acc: 88.75%)\n",
      "Epoch 92: Loss=2.87, Train Acc=99.58%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch92.pt (Val Acc: 88.12%)\n",
      "Epoch 93: Loss=3.08, Train Acc=99.65%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch93.pt (Val Acc: 88.12%)\n",
      "Epoch 94: Loss=2.50, Train Acc=99.65%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch94.pt (Val Acc: 88.75%)\n",
      "Epoch 95: Loss=2.50, Train Acc=99.51%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch95.pt (Val Acc: 88.75%)\n",
      "Epoch 96: Loss=2.32, Train Acc=99.58%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch96.pt (Val Acc: 88.75%)\n",
      "Epoch 97: Loss=2.71, Train Acc=99.24%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch97.pt (Val Acc: 88.75%)\n",
      "Epoch 98: Loss=2.81, Train Acc=99.44%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch98.pt (Val Acc: 88.12%)\n",
      "Epoch 99: Loss=2.61, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch99.pt (Val Acc: 88.75%)\n",
      "Epoch 100: Loss=2.36, Train Acc=99.58%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch100.pt (Val Acc: 89.38%)\n",
      "Epoch 101: Loss=2.65, Train Acc=99.65%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch101.pt (Val Acc: 89.38%)\n",
      "Epoch 102: Loss=2.90, Train Acc=99.44%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch102.pt (Val Acc: 89.38%)\n",
      "Epoch 103: Loss=2.63, Train Acc=99.51%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch103.pt (Val Acc: 88.75%)\n",
      "Epoch 104: Loss=2.58, Train Acc=99.44%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch104.pt (Val Acc: 88.12%)\n",
      "Epoch 105: Loss=2.75, Train Acc=99.51%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch105.pt (Val Acc: 88.12%)\n",
      "Epoch 106: Loss=2.44, Train Acc=99.79%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch106.pt (Val Acc: 88.12%)\n",
      "Epoch 107: Loss=2.20, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch107.pt (Val Acc: 88.75%)\n",
      "Epoch 108: Loss=2.12, Train Acc=99.79%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch108.pt (Val Acc: 88.75%)\n",
      "Epoch 109: Loss=2.56, Train Acc=99.38%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch109.pt (Val Acc: 87.50%)\n",
      "Epoch 110: Loss=2.25, Train Acc=99.44%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch110.pt (Val Acc: 88.12%)\n",
      "Epoch 111: Loss=2.17, Train Acc=99.51%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch111.pt (Val Acc: 88.75%)\n",
      "Epoch 112: Loss=2.48, Train Acc=99.65%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch112.pt (Val Acc: 88.75%)\n",
      "Epoch 113: Loss=2.52, Train Acc=99.51%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch113.pt (Val Acc: 88.12%)\n",
      "Epoch 114: Loss=2.16, Train Acc=99.79%, Val Acc=87.50%\n",
      "‚úÖ Saved model: Model_87_50_Epoch114.pt (Val Acc: 87.50%)\n",
      "Epoch 115: Loss=2.01, Train Acc=99.72%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch115.pt (Val Acc: 88.12%)\n",
      "Epoch 116: Loss=2.37, Train Acc=99.44%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch116.pt (Val Acc: 88.12%)\n",
      "Epoch 117: Loss=2.20, Train Acc=99.58%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch117.pt (Val Acc: 88.12%)\n",
      "Epoch 118: Loss=1.98, Train Acc=99.72%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch118.pt (Val Acc: 88.12%)\n",
      "Epoch 119: Loss=2.27, Train Acc=99.58%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch119.pt (Val Acc: 88.75%)\n",
      "Epoch 120: Loss=1.96, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch120.pt (Val Acc: 88.75%)\n",
      "Epoch 121: Loss=2.21, Train Acc=99.44%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch121.pt (Val Acc: 88.75%)\n",
      "Epoch 122: Loss=2.21, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch122.pt (Val Acc: 88.75%)\n",
      "Epoch 123: Loss=1.78, Train Acc=99.93%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch123.pt (Val Acc: 88.75%)\n",
      "Epoch 124: Loss=2.15, Train Acc=99.72%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch124.pt (Val Acc: 88.12%)\n",
      "Epoch 125: Loss=1.91, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch125.pt (Val Acc: 88.75%)\n",
      "Epoch 126: Loss=2.05, Train Acc=99.58%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch126.pt (Val Acc: 88.75%)\n",
      "Epoch 127: Loss=2.23, Train Acc=99.72%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch127.pt (Val Acc: 88.12%)\n",
      "Epoch 128: Loss=2.06, Train Acc=99.86%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch128.pt (Val Acc: 89.38%)\n",
      "Epoch 129: Loss=2.30, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch129.pt (Val Acc: 88.75%)\n",
      "Epoch 130: Loss=2.09, Train Acc=99.65%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch130.pt (Val Acc: 88.12%)\n",
      "Epoch 131: Loss=1.99, Train Acc=100.00%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch131.pt (Val Acc: 88.75%)\n",
      "Epoch 132: Loss=1.99, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch132.pt (Val Acc: 88.75%)\n",
      "Epoch 133: Loss=2.11, Train Acc=99.58%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch133.pt (Val Acc: 88.75%)\n",
      "Epoch 134: Loss=2.08, Train Acc=99.93%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch134.pt (Val Acc: 89.38%)\n",
      "Epoch 135: Loss=2.04, Train Acc=99.79%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch135.pt (Val Acc: 88.75%)\n",
      "Epoch 136: Loss=2.11, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch136.pt (Val Acc: 88.75%)\n",
      "Epoch 137: Loss=1.83, Train Acc=99.86%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch137.pt (Val Acc: 89.38%)\n",
      "Epoch 138: Loss=2.05, Train Acc=99.79%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch138.pt (Val Acc: 88.75%)\n",
      "Epoch 139: Loss=1.83, Train Acc=99.79%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch139.pt (Val Acc: 88.75%)\n",
      "Epoch 140: Loss=2.22, Train Acc=99.58%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch140.pt (Val Acc: 89.38%)\n",
      "Epoch 141: Loss=1.87, Train Acc=99.86%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch141.pt (Val Acc: 89.38%)\n",
      "Epoch 142: Loss=2.03, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch142.pt (Val Acc: 88.75%)\n",
      "Epoch 143: Loss=1.95, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch143.pt (Val Acc: 88.75%)\n",
      "Epoch 144: Loss=1.97, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch144.pt (Val Acc: 88.75%)\n",
      "Epoch 145: Loss=2.01, Train Acc=99.72%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch145.pt (Val Acc: 89.38%)\n",
      "Epoch 146: Loss=1.98, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch146.pt (Val Acc: 88.75%)\n",
      "Epoch 147: Loss=1.98, Train Acc=99.79%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch147.pt (Val Acc: 88.75%)\n",
      "Epoch 148: Loss=1.73, Train Acc=99.86%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch148.pt (Val Acc: 89.38%)\n",
      "Epoch 149: Loss=1.91, Train Acc=99.93%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch149.pt (Val Acc: 88.75%)\n",
      "Epoch 150: Loss=1.95, Train Acc=99.93%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch150.pt (Val Acc: 89.38%)\n",
      "Epoch 151: Loss=1.74, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch151.pt (Val Acc: 88.75%)\n",
      "Epoch 152: Loss=1.81, Train Acc=99.79%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch152.pt (Val Acc: 89.38%)\n",
      "Epoch 153: Loss=2.06, Train Acc=99.79%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch153.pt (Val Acc: 89.38%)\n",
      "Epoch 154: Loss=1.79, Train Acc=99.93%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch154.pt (Val Acc: 89.38%)\n",
      "Epoch 155: Loss=1.81, Train Acc=99.86%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch155.pt (Val Acc: 89.38%)\n",
      "Epoch 156: Loss=1.73, Train Acc=99.72%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch156.pt (Val Acc: 88.12%)\n",
      "Epoch 157: Loss=1.99, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch157.pt (Val Acc: 88.75%)\n",
      "Epoch 158: Loss=2.04, Train Acc=99.65%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch158.pt (Val Acc: 89.38%)\n",
      "Epoch 159: Loss=1.62, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch159.pt (Val Acc: 88.75%)\n",
      "Epoch 160: Loss=1.96, Train Acc=99.51%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch160.pt (Val Acc: 88.75%)\n",
      "Epoch 161: Loss=1.74, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch161.pt (Val Acc: 88.75%)\n",
      "Epoch 162: Loss=2.06, Train Acc=99.65%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch162.pt (Val Acc: 88.75%)\n",
      "Epoch 163: Loss=1.84, Train Acc=99.58%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch163.pt (Val Acc: 89.38%)\n",
      "Epoch 164: Loss=1.78, Train Acc=99.79%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch164.pt (Val Acc: 88.75%)\n",
      "Epoch 165: Loss=2.10, Train Acc=99.44%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch165.pt (Val Acc: 88.75%)\n",
      "Epoch 166: Loss=1.63, Train Acc=99.65%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch166.pt (Val Acc: 89.38%)\n",
      "Epoch 167: Loss=1.89, Train Acc=99.72%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch167.pt (Val Acc: 89.38%)\n",
      "Epoch 168: Loss=1.62, Train Acc=99.93%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch168.pt (Val Acc: 89.38%)\n",
      "Epoch 169: Loss=1.92, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch169.pt (Val Acc: 88.75%)\n",
      "Epoch 170: Loss=1.75, Train Acc=99.93%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch170.pt (Val Acc: 88.12%)\n",
      "Epoch 171: Loss=1.80, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch171.pt (Val Acc: 88.75%)\n",
      "Epoch 172: Loss=1.75, Train Acc=99.79%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch172.pt (Val Acc: 89.38%)\n",
      "Epoch 173: Loss=1.87, Train Acc=99.58%, Val Acc=88.12%\n",
      "‚úÖ Saved model: Model_88_12_Epoch173.pt (Val Acc: 88.12%)\n",
      "Epoch 174: Loss=1.68, Train Acc=99.79%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch174.pt (Val Acc: 88.75%)\n",
      "Epoch 175: Loss=1.80, Train Acc=99.93%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch175.pt (Val Acc: 88.75%)\n",
      "Epoch 176: Loss=1.47, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch176.pt (Val Acc: 88.75%)\n",
      "Epoch 177: Loss=1.82, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch177.pt (Val Acc: 88.75%)\n",
      "Epoch 178: Loss=1.64, Train Acc=100.00%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch178.pt (Val Acc: 89.38%)\n",
      "Epoch 179: Loss=1.98, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch179.pt (Val Acc: 88.75%)\n",
      "Epoch 180: Loss=1.51, Train Acc=99.79%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch180.pt (Val Acc: 89.38%)\n",
      "Epoch 181: Loss=2.06, Train Acc=99.44%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch181.pt (Val Acc: 89.38%)\n",
      "Epoch 182: Loss=1.67, Train Acc=99.93%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch182.pt (Val Acc: 88.75%)\n",
      "Epoch 183: Loss=1.81, Train Acc=99.86%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch183.pt (Val Acc: 89.38%)\n",
      "Epoch 184: Loss=1.91, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch184.pt (Val Acc: 88.75%)\n",
      "Epoch 185: Loss=1.81, Train Acc=99.72%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch185.pt (Val Acc: 89.38%)\n",
      "Epoch 186: Loss=1.76, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch186.pt (Val Acc: 88.75%)\n",
      "Epoch 187: Loss=1.82, Train Acc=99.93%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch187.pt (Val Acc: 89.38%)\n",
      "Epoch 188: Loss=1.73, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch188.pt (Val Acc: 88.75%)\n",
      "Epoch 189: Loss=1.75, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch189.pt (Val Acc: 88.75%)\n",
      "Epoch 190: Loss=1.53, Train Acc=99.86%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch190.pt (Val Acc: 88.75%)\n",
      "Epoch 191: Loss=1.61, Train Acc=99.93%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch191.pt (Val Acc: 88.75%)\n",
      "Epoch 192: Loss=1.85, Train Acc=99.65%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch192.pt (Val Acc: 89.38%)\n",
      "Epoch 193: Loss=1.83, Train Acc=99.93%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch193.pt (Val Acc: 89.38%)\n",
      "Epoch 194: Loss=1.72, Train Acc=99.93%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch194.pt (Val Acc: 89.38%)\n",
      "Epoch 195: Loss=1.87, Train Acc=99.58%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch195.pt (Val Acc: 88.75%)\n",
      "Epoch 196: Loss=1.77, Train Acc=99.65%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch196.pt (Val Acc: 88.75%)\n",
      "Epoch 197: Loss=1.86, Train Acc=99.72%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch197.pt (Val Acc: 88.75%)\n",
      "Epoch 198: Loss=2.21, Train Acc=99.51%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch198.pt (Val Acc: 89.38%)\n",
      "Epoch 199: Loss=1.90, Train Acc=99.65%, Val Acc=88.75%\n",
      "‚úÖ Saved model: Model_88_75_Epoch199.pt (Val Acc: 88.75%)\n",
      "Epoch 200: Loss=1.98, Train Acc=99.72%, Val Acc=89.38%\n",
      "‚úÖ Saved model: Model_89_38_Epoch200.pt (Val Acc: 89.38%)\n",
      "\n",
      "‚úÖ Final Test Accuracy: 89.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score  # ‚úÖ Needed for final test acc\n",
    "from tqdm import tqdm  # ‚úÖ Correct import\n",
    "import os\n",
    "\n",
    "# ‚úÖ Ensure this is defined earlier in the notebook\n",
    "# from your_model_file import YAMNet1DCNN_Improved\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YAMNet1DCNN_Improved().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=15,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 200\n",
    "no_improve_epochs = 0\n",
    "saved_model_name = None\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += (preds.argmax(1) == yb).sum().item()\n",
    "\n",
    "    train_acc = 100. * correct / len(train_loader.dataset)\n",
    "\n",
    "    # üîç Validation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            val_correct += (preds.argmax(1) == yb).sum().item()\n",
    "            val_total += yb.size(0)\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss={total_loss:.2f}, Train Acc={train_acc:.2f}%, Val Acc={val_acc:.2f}%\")\n",
    "\n",
    "    # ‚úÖ Save model if val_acc >= 85 (allow duplicates with epoch number)\n",
    "    if val_acc >= 85:\n",
    "        val_str = f\"{val_acc:.2f}\".replace('.', '_')\n",
    "        saved_model_name = f\"Model_{val_str}_Epoch{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), saved_model_name)\n",
    "        print(f\"‚úÖ Saved model: {saved_model_name} (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"‚õî Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for xb, _ in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model(xb)\n",
    "        all_preds.append(preds.cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds).argmax(1).numpy()\n",
    "acc = accuracy_score(y_test, all_preds)\n",
    "\n",
    "print(f\"\\n‚úÖ Final Test Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375bc14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Model_90_00_Epoch105.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 26.96it/s]\n",
      "Testing Model_90_00_Epoch114.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 26.60it/s]\n",
      "Testing Model_90_00_Epoch93.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 26.71it/s]\n",
      "Testing Model_90_00_Epoch99.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 26.84it/s]\n",
      "Testing Model_90.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 26.74it/s]\n",
      "Testing Model_91.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 26.30it/s]\n",
      "Testing Model_92.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 26.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Comparison Results:\n",
      "Model_90_00_Epoch114.pt             ‚Üí Test Accuracy: 89.00%\n",
      "Model_90_00_Epoch99.pt              ‚Üí Test Accuracy: 89.00%\n",
      "Model_92.pt                         ‚Üí Test Accuracy: 88.75%\n",
      "Model_90_00_Epoch93.pt              ‚Üí Test Accuracy: 88.50%\n",
      "Model_90_00_Epoch105.pt             ‚Üí Test Accuracy: 88.25%\n",
      "Model_90.pt                         ‚Üí Test Accuracy: 85.50%\n",
      "Model_91.pt                         ‚Üí Test Accuracy: 85.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_class = YAMNet1DCNN_Improved\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Match all model files like Model_91_25_Epoch58.pt\n",
    "model_files = [f for f in os.listdir() if f.startswith(\"Model_\") and f.endswith(\".pt\")]\n",
    "\n",
    "# Optional: sort by val_acc descending (if filenames use Model_91_88_Epoch58.pt format)\n",
    "def extract_val_acc(file):\n",
    "    match = re.search(r'Model_(\\d+)_(\\d+)', file)\n",
    "    if match:\n",
    "        major, minor = match.groups()\n",
    "        return float(f\"{major}.{minor}\")\n",
    "    return 0\n",
    "\n",
    "model_files.sort(key=extract_val_acc, reverse=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_file in model_files:\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(test_loader, desc=f\"Testing {model_file}\"):\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb)\n",
    "            all_preds.extend(preds.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds) * 100\n",
    "    results.append((model_file, acc))\n",
    "\n",
    "# Print sorted results\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nüìä Model Comparison Results:\")\n",
    "for name, acc in results:\n",
    "    print(f\"{name:<35} ‚Üí Test Accuracy: {acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
