{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f525359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "667d5f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            filename  fold  target        category  esc10  src_file take\n",
      "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
      "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
      "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
      "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
      "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A\n"
     ]
    }
   ],
   "source": [
    "# üìÅ Step 3: Load ESC-50 CSV\n",
    "# ‚úÖ Update these paths with your actual file structure\n",
    "CSV_PATH = r'C:\\Users\\nasrr\\Desktop\\CNN_Farah\\Farah\\ESC-50-master\\ESC-50-master\\meta\\esc50.csv'\n",
    "AUDIO_PATH = r'C:\\Users\\nasrr\\Desktop\\CNN_Farah\\Farah\\ESC-50-master\\ESC-50-master\\audio'\n",
    "\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "148c6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîâ Step 4: Load YAMNet model\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424311db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:41<00:00, 48.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done:  (2000, 1024) (2000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# üéß Step 5: Convert audio to embeddings (X) and labels (y)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    file_path = os.path.join(AUDIO_PATH, row['filename'])\n",
    "    label = row['target']\n",
    "\n",
    "    try:\n",
    "        waveform, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "        waveform = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
    "\n",
    "        _, embeddings, _ = yamnet_model(waveform)\n",
    "        mean_embedding = tf.reduce_mean(embeddings, axis=0).numpy()\n",
    "\n",
    "        X.append(mean_embedding)\n",
    "        y.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {file_path} ‚Üí {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"‚úÖ Done: \", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3a9482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1600, 1024) Test: (400, 1024)\n"
     ]
    }
   ],
   "source": [
    "# üß† Step 6: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e2c7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "\n",
    "augment = torch.nn.Sequential(\n",
    "    T.FrequencyMasking(freq_mask_param=10),\n",
    "    T.TimeMasking(time_mask_param=20)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5663b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:47<00:00, 42.28it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_FRAMES = 100  # We'll fix all embeddings to this length\n",
    "\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    file_path = os.path.join(AUDIO_PATH, row['filename'])\n",
    "    label = row['target']\n",
    "\n",
    "    try:\n",
    "        waveform, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "        waveform = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
    "\n",
    "        _, embeddings, _ = yamnet_model(waveform)\n",
    "        emb_np = embeddings.numpy()  # shape: (frames, 1024)\n",
    "\n",
    "        # Pad/truncate to MAX_FRAMES\n",
    "        if emb_np.shape[0] < MAX_FRAMES:\n",
    "            pad_width = MAX_FRAMES - emb_np.shape[0]\n",
    "            emb_np = np.pad(emb_np, ((0, pad_width), (0, 0)), mode='constant')\n",
    "        else:\n",
    "            emb_np = emb_np[:MAX_FRAMES, :]\n",
    "\n",
    "        X_seq.append(emb_np)\n",
    "        y_seq.append(label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {file_path} ‚Üí {e}\")\n",
    "\n",
    "X_seq = np.array(X_seq)  # shape: (N, 100, 1024)\n",
    "y_seq = np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4aae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, stratify=y_seq, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# DataLoaders\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "val_pct = 0.1\n",
    "val_size = int(val_pct * len(train_ds))\n",
    "train_size = len(train_ds) - val_size\n",
    "\n",
    "train_set, val_set = random_split(train_ds, [train_size, val_size])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9733b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class YAMNet1DCNN_Improved(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1024, 512, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(512, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(256, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.75)  # Slightly higher for better regularization\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, 100, 1024) ‚Üí (B, 1024, 100)\n",
    "        x = self.pool1(F.gelu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.gelu(self.bn2(self.conv2(x))))\n",
    "        x = F.gelu(self.bn3(self.conv3(x)))\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b84025f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YAMNet1DCNN_Improved().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91a0d584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Model_90.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 27.89it/s]\n",
      "Testing Model_91.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 27.93it/s]\n",
      "Testing Model_92.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 27.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Comparison Results:\n",
      "Model_92.pt     ‚Üí Test Accuracy: 88.75%\n",
      "Model_90.pt     ‚Üí Test Accuracy: 85.50%\n",
      "Model_91.pt     ‚Üí Test Accuracy: 85.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model_class = YAMNet1DCNN_Improved\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# List all models matching pattern Model_XX.pt\n",
    "model_files = sorted(\n",
    "    [f for f in os.listdir() if re.match(r'Model_\\d+\\.pt', f)],\n",
    "    key=lambda x: int(re.findall(r'\\d+', x)[0])\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_file in model_files:\n",
    "    val_acc_label = int(re.findall(r'\\d+', model_file)[0])  # Get 90, 91, etc.\n",
    "    \n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(test_loader, desc=f\"Testing {model_file}\"):\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb)\n",
    "            all_preds.extend(preds.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    test_acc = accuracy_score(all_labels, all_preds) * 100\n",
    "    results.append((model_file, test_acc))\n",
    "\n",
    "# Sort results by accuracy descending\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nüìä Model Comparison Results:\")\n",
    "for name, acc in results:\n",
    "    print(f\"{name:<15} ‚Üí Test Accuracy: {acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
